{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_spark",
      "provenance": [],
      "authorship_tag": "ABX9TyMm+j9WGpvzpsoZhenc0I2s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edcalderin/BigDataEngineering_ICARO/blob/master/spark/1_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqJ0fq70T0gI"
      },
      "source": [
        "%%bash\n",
        "apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "wget -q http://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCmGtgKT5Mk"
      },
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-2.4.7-bin-hadoop2.7'\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7QwWCFCVTe8",
        "outputId": "c40258b7-7ce6-4cf4-da44-8cb949364274"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjvvF777UXmf",
        "outputId": "3527701a-f7a5-447e-b0de-7d0802294a88"
      },
      "source": [
        "!ls drive/MyDrive/'Big Data Engineering'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Big Data Engineering - 2 de Febrero.mp4'\n",
            "'Big Data Engineering - 8 de Febrero.mp4'\n",
            "'Copia de Icaro - Data Engineering Foundations (Clase 1).gslides'\n",
            "'Copia de Icaro - Data Engineering Foundations (Clase 3).gslides'\n",
            "'Copia de Icaro - Data Engineering Foundations (Clase 4).gslides'\n",
            "'Copia de Icaro - Data Engineering Foundations (Clase 5).gslides'\n",
            "'Copia de Icaro - Data Engineering Foundations (Clase 6).gslides'\n",
            "'Copia de InstalacioÃÅn Docker.gdoc'\n",
            "'Copia de quijote.txt'\n",
            "'Data Engineering Foundations (Clase 2).gslides'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QOLckB4VpPc"
      },
      "source": [
        "PATH = 'drive/MyDrive/Big_Data_Engineering'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0-a4OgHVi14",
        "outputId": "d9c477b1-8327-4903-830d-abb3416b8ae4"
      },
      "source": [
        "quijote = spark.read.text(f'{PATH}/quijote.txt')\n",
        "stop_words = spark.read.text(f'{PATH}/spanish_stop_words.txt')\n",
        "#veamos que efectivamente es un DataFrame\n",
        "print(type(quijote))\n",
        "print(type(stop_words))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnMD2QzvWctb",
        "outputId": "61e4f14f-d04a-4eba-9903-6223095110af"
      },
      "source": [
        "print(quijote.printSchema())\n",
        "print(stop_words.printSchema())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "None\n",
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3yxSY7RWhq5"
      },
      "source": [
        "quijote_rdd = quijote.rdd\n",
        "stop_words_rdd = stop_words.rdd"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxEox99LWi9h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}